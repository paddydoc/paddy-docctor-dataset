{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"train_path = '/kaggle/input/paddy-disease-classification-2/train_images/'\ntest_path  = '/kaggle/input/paddy-disease-classification-2/test_images/'\n\n!du --inodes '/kaggle/input/paddy-disease-classification-2/train_images/'\n!du --inodes '/kaggle/input/paddy-disease-classification-2/test_images/'\n\nimport glob\nfrom pathlib import Path\n\nfor filepath in glob.glob(train_path + '/*/'):\n    files = glob.glob(filepath + '*')\n    print(f\"{len(files)} \\t {Path(filepath).name}\")\n\nfiles = glob.glob(test_path + '/*')\nprint(f\"{len(files)} \\t {Path(test_path).name}\") ","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:21:18.648152Z","iopub.execute_input":"2022-07-18T16:21:18.648501Z","iopub.status.idle":"2022-07-18T16:21:24.503901Z","shell.execute_reply.started":"2022-07-18T16:21:18.648469Z","shell.execute_reply":"2022-07-18T16:21:24.502692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pickle\nimport cv2\nimport os\n\nfrom os import listdir\nfrom sklearn.preprocessing import LabelBinarizer\nfrom tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.layers import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation, Flatten, Dropout, Dense\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import plot_model\n\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nimport keras\nkeras.__version__\nfrom psutil import virtual_memory\n\nSEED = 123\nEPOCHS = 100\nINIT_LR = 1e-3\nBS = 32\ndefault_image_size = tuple((256, 256))\nimage_size = 0\nwidth = 256\nheight = 256\ndepth = 3\n\nn_classes = len(glob.glob(train_path + '/*/'))\nprint(n_classes)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:21:24.506337Z","iopub.execute_input":"2022-07-18T16:21:24.506717Z","iopub.status.idle":"2022-07-18T16:21:24.519549Z","shell.execute_reply.started":"2022-07-18T16:21:24.506679Z","shell.execute_reply":"2022-07-18T16:21:24.518579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom keras.models import Model\n#from keras.optimizers import Adam\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.layers import Dense, Dropout, Flatten\nfrom pathlib import Path\nimport numpy as np\n\n#https://www.learndatasci.com/tutorials/hands-on-transfer-learning-keras/\ndef create_model(input_shape, n_classes, optimizer='rmsprop', fine_tune=0):\n    \"\"\"\n    Compiles a model integrated with VGG16 pretrained layers\n    \n    input_shape: tuple - the shape of input images (width, height, channels)\n    n_classes: int - number of classes for the output layer\n    optimizer: string - instantiated optimizer to use for training. Defaults to 'RMSProp'\n    fine_tune: int - The number of pre-trained layers to unfreeze.\n                If set to 0, all pretrained layers will freeze during training\n    \"\"\"\n    \n    # Pretrained convolutional layers are loaded using the Imagenet weights.\n    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n    conv_base = VGG16(include_top=False,\n                     weights='imagenet', \n                     input_shape=input_shape)\n    \n    # Defines how many layers to freeze during training.\n    # Layers in the convolutional base are switched from trainable to non-trainable\n    # depending on the size of the fine-tuning parameter.\n    if fine_tune > 0:\n        for layer in conv_base.layers[:-fine_tune]:\n            layer.trainable = False\n    else:\n        for layer in conv_base.layers:\n            layer.trainable = False\n\n    # Create a new 'top' of the model (i.e. fully-connected layers).\n    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n    top_model = conv_base.output\n    top_model = Flatten(name=\"flatten\")(top_model)\n    top_model = Dense(1024, activation='relu')(top_model)\n    top_model = Dropout(0.2)(top_model)\n    \n    output_layer = Dense(n_classes, activation='softmax')(top_model)\n    \n#     model.add(Dense(1024))\n#     model.add(Activation(\"relu\"))\n#     model.add(BatchNormalization())\n#     model.add(Dropout(0.5))\n#     model.add(Dense(n_classes))\n#     model.add(Activation(\"softmax\"))\n    \n    \n    # Group the convolutional base and new fully-connected layers into a Model object.\n    model = Model(inputs=conv_base.input, outputs=output_layer)\n\n    # Compiles the model for training.\n    model.compile(optimizer=optimizer, \n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:21:24.521057Z","iopub.execute_input":"2022-07-18T16:21:24.521936Z","iopub.status.idle":"2022-07-18T16:21:24.535922Z","shell.execute_reply.started":"2022-07-18T16:21:24.521901Z","shell.execute_reply":"2022-07-18T16:21:24.534895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    model = Sequential()\n    inputShape = (height, width, depth)\n    chanDim = -1\n    print(K.image_data_format())\n    if K.image_data_format() == \"channels_first\":\n        inputShape = (depth, height, width)\n        chanDim = 1\n    model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization(axis=chanDim))\n    model.add(MaxPooling2D(pool_size=(3, 3)))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization(axis=chanDim))\n    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization(axis=chanDim))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization(axis=chanDim))\n    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization(axis=chanDim))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(1024))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(n_classes))\n    model.add(Activation(\"softmax\"))\n    \n    opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n    # distribution\n    model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n    return model\nmodel = get_model()\n\n#plot_model(model, '/kaggle/working/model.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:21:24.538801Z","iopub.execute_input":"2022-07-18T16:21:24.53958Z","iopub.status.idle":"2022-07-18T16:21:24.712451Z","shell.execute_reply.started":"2022-07-18T16:21:24.539545Z","shell.execute_reply":"2022-07-18T16:21:24.711533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (256, 256, 3)\n\n# Use a smaller learning rate\noptim_2 = Adam(lr=0.0001)\n\n# Re-compile the model, this time leaving the last 2 layers unfrozen for Fine-Tuning\nvgg16_model = create_model(input_shape, n_classes, optim_2, fine_tune=2)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:21:24.713739Z","iopub.execute_input":"2022-07-18T16:21:24.714102Z","iopub.status.idle":"2022-07-18T16:21:25.026826Z","shell.execute_reply.started":"2022-07-18T16:21:24.714066Z","shell.execute_reply":"2022-07-18T16:21:25.025657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_datagen = ImageDataGenerator(featurewise_center=False,\n                 samplewise_center=False,\n                 featurewise_std_normalization=False,\n                 samplewise_std_normalization=False,\n                 zca_whitening=False,\n                 rotation_range=5,\n                 shear_range=0.2,\n                 zoom_range=0.2,\n                 width_shift_range=0.05,\n                 height_shift_range=0.05,\n                 channel_shift_range=0.,\n                 fill_mode='nearest',\n                 horizontal_flip=True,\n                 vertical_flip=False,\n                 rescale=1./255,\n                                   validation_split=0.2)\n\ntrain_generator = image_datagen.flow_from_directory(    \n    directory = train_path,\n    subset='training',\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=SEED)\n\nvalid_generator = image_datagen.flow_from_directory(    \n    directory=train_path,\n    subset='validation',\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=SEED)\n\ntest_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(    \n    directory=test_path,\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    batch_size=1,\n    classes=['.'],\n    class_mode=None,\n    shuffle=False,\n    seed=SEED)\n\nprint(train_generator.class_indices)\nprint(test_generator.samples)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:21:25.028263Z","iopub.execute_input":"2022-07-18T16:21:25.028636Z","iopub.status.idle":"2022-07-18T16:21:25.683257Z","shell.execute_reply.started":"2022-07-18T16:21:25.028597Z","shell.execute_reply":"2022-07-18T16:21:25.682187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install livelossplot","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:21:25.684801Z","iopub.execute_input":"2022-07-18T16:21:25.68516Z","iopub.status.idle":"2022-07-18T16:21:35.620653Z","shell.execute_reply.started":"2022-07-18T16:21:25.685125Z","shell.execute_reply":"2022-07-18T16:21:35.619492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from livelossplot.inputs.keras import PlotLossesCallback\n\nplot_loss_1 = PlotLossesCallback()\n\n# ModelCheckpoint callback - save best weights\ntl_checkpoint_1 = ModelCheckpoint(filepath='vgg_model_ft.weights.best.hdf5',\n                                  save_best_only=True,\n                                  verbose=1)\n\n# EarlyStopping\nearly_stop = EarlyStopping(monitor='val_loss',\n                           patience=10,\n                           restore_best_weights=True,\n                           mode='min')","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:21:35.622942Z","iopub.execute_input":"2022-07-18T16:21:35.623333Z","iopub.status.idle":"2022-07-18T16:21:35.630744Z","shell.execute_reply.started":"2022-07-18T16:21:35.623292Z","shell.execute_reply":"2022-07-18T16:21:35.629736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nplot_loss_2 = PlotLossesCallback()\n\nSTEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n\n# Retrain model with fine-tuning\nvgg16_history = vgg16_model.fit_generator(generator = train_generator,\n                                  steps_per_epoch = STEP_SIZE_TRAIN,\n                                  validation_data = valid_generator,\n                                  validation_steps = STEP_SIZE_VALID,\n                                  callbacks=[tl_checkpoint_1, early_stop, plot_loss_2],\n                                  verbose=1,epochs=EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T06:06:26.704759Z","iopub.execute_input":"2022-07-18T06:06:26.705112Z","iopub.status.idle":"2022-07-18T06:06:48.536194Z","shell.execute_reply.started":"2022-07-18T06:06:26.705075Z","shell.execute_reply":"2022-07-18T06:06:48.534811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !ls -l /kaggle/input","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:21:42.376034Z","iopub.execute_input":"2022-07-18T16:21:42.376391Z","iopub.status.idle":"2022-07-18T16:21:42.38139Z","shell.execute_reply.started":"2022-07-18T16:21:42.37636Z","shell.execute_reply":"2022-07-18T16:21:42.380164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_path_new = '/kaggle/input/pd2-test-images-labels/'\n!du --inodes '/kaggle/input/pd2-test-images-labels/'\n\nfor filepath in glob.glob(test_path_new + '/*/'):\n    files = glob.glob(filepath + '*')\n    print(f\"{len(files)} \\t {Path(filepath).name}\")","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:21:56.67816Z","iopub.execute_input":"2022-07-18T16:21:56.678532Z","iopub.status.idle":"2022-07-18T16:21:58.609197Z","shell.execute_reply.started":"2022-07-18T16:21:56.678485Z","shell.execute_reply":"2022-07-18T16:21:58.60795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_subset = sorted(os.listdir(test_path_new))#[:10] # Using only the first 10 classes\nclass_subset","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:22:04.651897Z","iopub.execute_input":"2022-07-18T16:22:04.652333Z","iopub.status.idle":"2022-07-18T16:22:04.668177Z","shell.execute_reply.started":"2022-07-18T16:22:04.652295Z","shell.execute_reply":"2022-07-18T16:22:04.667308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_generator_vgg = ImageDataGenerator(rescale=1./255).flow_from_directory(    \n    directory=test_path_new,\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    batch_size=1,\n    classes=class_subset,\n    class_mode=None,\n    shuffle=False,\n    seed=SEED)\n\nvgg16_model.load_weights('vgg_model_ft.weights.best.hdf5') # initialize the best trained weights\n# vgg16_model.load_weights('../input/pd2vgg16weightsbest/vgg_model_ft.weights.best.hdf5') # initialize the best trained weights\n\nvgg_preds_ft = vgg16_model.predict(test_generator_vgg)\nvgg_pred_classes_ft = np.argmax(vgg_preds_ft, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:22:50.428451Z","iopub.execute_input":"2022-07-18T16:22:50.429238Z","iopub.status.idle":"2022-07-18T16:23:28.988116Z","shell.execute_reply.started":"2022-07-18T16:22:50.429202Z","shell.execute_reply":"2022-07-18T16:23:28.987131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\nclass_names = test_generator_vgg.class_indices.keys()\n\ntrue_classes = test_generator_vgg.classes\n\nvgg_acc_ft = accuracy_score(true_classes, vgg_pred_classes_ft)\nprint(\"VGG16 Model Accuracy with Fine-Tuning: {:.2f}%\".format(vgg_acc_ft * 100))\n\ncls_report = classification_report(true_classes, vgg_pred_classes_ft, \n                                   target_names=class_names, digits=5)\nprint(cls_report)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:40:33.626898Z","iopub.execute_input":"2022-07-18T16:40:33.627241Z","iopub.status.idle":"2022-07-18T16:40:33.644589Z","shell.execute_reply.started":"2022-07-18T16:40:33.627211Z","shell.execute_reply":"2022-07-18T16:40:33.643574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\n# Get the names of the ten classes\nclass_names = test_generator_vgg.class_indices.keys()\n\ndef plot_heatmap(y_true, y_pred, class_names, ax, title):\n    cm = confusion_matrix(y_true, y_pred)\n    sns.heatmap(\n        cm, \n        annot=True, \n        square=True, \n        xticklabels=class_names, \n        yticklabels=class_names,\n        fmt='d', \n        cmap=plt.cm.Blues,\n        cbar=False,\n        ax=ax\n    )\n    #ax.set_title(title, fontsize=16)\n    ax.set_xticklabels(ax.get_xticklabels(), fontsize=12, rotation=45, ha=\"right\")\n    ax.set_yticklabels(ax.get_yticklabels(), fontsize=12)\n    ax.set_ylabel('True Label', fontsize=12)\n    ax.set_xlabel('Predicted Label', fontsize=12)\n\nfig, ax = plt.subplots(1, 1, figsize=(6, 6))\n\nplot_heatmap(true_classes, vgg_pred_classes_ft, class_names, ax, title=\"VGG16\")    \n\n#fig.suptitle(\"Confusion Matrix Model Comparison\", fontsize=12)\n#fig.tight_layout()\n#fig.subplots_adjust(top=1.25)\nplt.show()\ncm = confusion_matrix(true_classes, vgg_pred_classes_ft)\nprint(cm)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:41:18.245334Z","iopub.execute_input":"2022-07-18T16:41:18.245687Z","iopub.status.idle":"2022-07-18T16:41:19.176991Z","shell.execute_reply.started":"2022-07-18T16:41:18.245658Z","shell.execute_reply":"2022-07-18T16:41:19.176022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n# STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n# STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n# history = model.fit_generator(generator = train_generator,\n#                     steps_per_epoch = STEP_SIZE_TRAIN,\n#                     validation_data = valid_generator,\n#                     validation_steps = STEP_SIZE_VALID,\n#                     epochs=EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T06:06:49.472975Z","iopub.status.idle":"2022-07-18T06:06:49.473721Z","shell.execute_reply.started":"2022-07-18T06:06:49.473449Z","shell.execute_reply":"2022-07-18T06:06:49.473471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory = vgg16_history\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n#Train and validation accuracy\nplt.plot(epochs, acc, 'b', label='Training accurarcy')\nplt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\nplt.title('Training and Validation accurarcy')\nplt.legend()\n\nplt.figure()\n#Train and validation loss\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:42:50.411795Z","iopub.execute_input":"2022-07-18T16:42:50.413734Z","iopub.status.idle":"2022-07-18T16:42:50.438944Z","shell.execute_reply.started":"2022-07-18T16:42:50.413682Z","shell.execute_reply":"2022-07-18T16:42:50.437379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\ntest_generator.reset()\npred = vgg16_model.predict_generator(test_generator,\n                               steps=STEP_SIZE_TEST,\n                               verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:45:23.435618Z","iopub.execute_input":"2022-07-18T16:45:23.436169Z","iopub.status.idle":"2022-07-18T16:45:59.624319Z","shell.execute_reply.started":"2022-07-18T16:45:23.436124Z","shell.execute_reply":"2022-07-18T16:45:59.623427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, acc = vgg16_model.evaluate_generator(test_generator, steps=STEP_SIZE_TEST, verbose=1)\nprint(acc, loss)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:46:06.633424Z","iopub.execute_input":"2022-07-18T16:46:06.633979Z","iopub.status.idle":"2022-07-18T16:46:06.900599Z","shell.execute_reply.started":"2022-07-18T16:46:06.633936Z","shell.execute_reply":"2022-07-18T16:46:06.897179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series(train_generator.classes).value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:46:29.591332Z","iopub.execute_input":"2022-07-18T16:46:29.591828Z","iopub.status.idle":"2022-07-18T16:46:29.610264Z","shell.execute_reply.started":"2022-07-18T16:46:29.591782Z","shell.execute_reply":"2022-07-18T16:46:29.609174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series(test_generator.classes).value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:46:33.27901Z","iopub.execute_input":"2022-07-18T16:46:33.279363Z","iopub.status.idle":"2022-07-18T16:46:33.289348Z","shell.execute_reply.started":"2022-07-18T16:46:33.279332Z","shell.execute_reply":"2022-07-18T16:46:33.288482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_class_indices=np.argmax(pred,axis=1)\nlabels = (train_generator.class_indices)\n\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]\n\npd.Series(predictions).value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:46:40.388901Z","iopub.execute_input":"2022-07-18T16:46:40.389249Z","iopub.status.idle":"2022-07-18T16:46:40.40671Z","shell.execute_reply.started":"2022-07-18T16:46:40.38922Z","shell.execute_reply":"2022-07-18T16:46:40.405485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames=test_generator.filenames\n\nresults=pd.DataFrame({\"image_id\":filenames,\n                      \"label\":predictions})\nresults.image_id = results.image_id.str.replace('./', '')\nresults.to_csv(\"submission.csv\",index=False)\nresults.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:46:46.96116Z","iopub.execute_input":"2022-07-18T16:46:46.961507Z","iopub.status.idle":"2022-07-18T16:46:46.994004Z","shell.execute_reply.started":"2022-07-18T16:46:46.961476Z","shell.execute_reply":"2022-07-18T16:46:46.993034Z"},"trusted":true},"execution_count":null,"outputs":[]}]}